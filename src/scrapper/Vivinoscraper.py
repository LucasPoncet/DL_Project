import requests
import pandas as pd
import math
import time
import matplotlib.pyplot as plt
import numpy as np
import ast  # For parsing the 'cepages' string safely


import requests
import pandas as pd
import math
import time
import matplotlib.pyplot as plt
import numpy as np


HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0",
    "Accept": "application/json"
}

BASE_PARAMS = {
    "country_code": "FR",
    "country_codes[]": "fr",
    "currency_code": "EUR",
    "grape_filter": "varietal",
    "min_rating": "1",
    "order_by": "price",
    "order": "asc",
    "price_range_min": "0",
    "price_range_max": "500000",
    "wine_type_ids[]": "1"
}

def scrape_all_vivino_pages(pmin,pmax):
    url = "https://www.vivino.com/api/explore/explore"
    all_results = []

    # Step 1: Request page 1 to find out total number of pages
    params = BASE_PARAMS.copy()
    params["page"] = 1

    params["price_range_min"] = pmin
    params["price_range_max"] = pmax
    
    response = requests.get(url, headers=HEADERS, params=params)
    if response.status_code != 200:
        raise Exception(f"Initial request failed with status code {response.status_code}")

    data = response.json()
    total_wines = data["explore_vintage"]["records_matched"]
    wines_per_page = len(data["explore_vintage"]["matches"])
    total_pages = math.ceil(total_wines / wines_per_page)

    print(f"üîç Found {total_wines} wines across {total_pages} pages.")

    # Step 2: Loop through all pages
    for page in range(1, total_pages + 1):
        print(f"üìÑ Scraping page {page}/{total_pages}")
        params["page"] = page
        response = requests.get(url, headers=HEADERS, params=params)

        if response.status_code != 200:
            print(f"‚ö†Ô∏è Skipping page {page} due to error {response.status_code}")
            continue

        matches = response.json()["explore_vintage"]["matches"]
        for t in matches:
            try:
                all_results.append((
                    t["vintage"]["wine"]["winery"]["name"],
                    f'{t["vintage"]["wine"]["name"]} {t["vintage"]["year"]}',
                    t["vintage"]["year"],
                    t["vintage"]["statistics"]["ratings_average"],
                    t["vintage"]["statistics"]["ratings_count"],
                    t['vintage']['statistics']['wine_ratings_average'],
                    t['vintage']['statistics']['wine_ratings_count'],
                    t["vintage"]["wine"]["region"]["seo_name"],
                    t["price"]["amount"],
                    t['vintage']['wine']['style']['grapes']
                ))
            except Exception as e:
                print("X Skipping a wine due to missing data:", e)

        time.sleep(0.5)  # Be polite to the server

    return pd.DataFrame(all_results, columns=[
        'Winery', 'Wine', 'vintage', 'vintage_rating', 'vintage_rating_count', 'wine_rating', 'wine_rating_count', 'region', 'price','cepages', ])
    
# lauch the scraper

df0 = scrape_all_vivino_pages(0,50000) #Vivino doesn't allow us to scrap to many wines at once so we have to split the scraping in several intervals that follow the prices
df1 = scrape_all_vivino_pages(15,500000)
df2 = scrape_all_vivino_pages(21.8,500000)
df3 = scrape_all_vivino_pages(30.1,500000)
df4 = scrape_all_vivino_pages(42.1,500000)
df5 = scrape_all_vivino_pages(62.1,500000)
df6 = scrape_all_vivino_pages(107.1,500000)
df7 = scrape_all_vivino_pages(288.1,500000)


# Combine all dataframes into one and clean it up
df_combined = pd.concat([df0, df1, df2, df3, df4, df5, df6, df7], ignore_index=True)
df_combined = df_combined.drop_duplicates(subset=['Wine', 'vintage'], keep='first')
df_combined = df_combined.sort_values(by="price")
df_combined.shape



# Main cepage selection

def extract_dominant(sep_str: str | float) -> str | None:
    """Return first-grape 'seo_name' from a cepages literal‚Äêstring.

    Handles NaNs, empty lists, or malformed rows safely.
    """
    if pd.isna(sep_str):
        return None
    try:
        # literal_eval turns the single-quoted Python-style string
        # into a real list[dict] without executing any code
        grape_list = ast.literal_eval(sep_str)
        if isinstance(grape_list, list) and grape_list:
            return grape_list[0].get("seo_name")   # dominant grape
    except (ValueError, SyntaxError):
        pass
    return None

# Add a new column containing only the first c√©page name
df_combined['cepages'] = df_combined['cepages'].apply(extract_dominant)

df_combined = df_combined.dropna(subset=['cepages'])  # Remove rows with NaN in 'cepages'

# Ensure 'vintage' is numeric
df_combined['vintage'] = pd.to_numeric(df_combined['vintage'], errors='coerce')
vintage_counts = df_combined['vintage'].value_counts().sort_index()

df_combined.to_parquet("wines_vivino.parquet", index=False)  # Save the cleaned DataFrame to a Parquet file


# VISUALIZATION


# Plotting the distribution of wines by vintage
plt.figure(figsize=(12, 5))
vintage_counts.plot(kind='bar', color='skyblue')
plt.title("Number of Wines per Vintage")
plt.xlabel("Vintage Year")
plt.ylabel("Number of Wines")
plt.xticks(rotation=45)
plt.tight_layout()
plt.grid(axis='y')
plt.show()





# TOP 90% REGIONS

# Count wines per region
region_counts = df_combined["region"].value_counts()

# Compute cumulative wine share per region
cumulative_share = region_counts.cumsum() / region_counts.sum()

# Keep only regions that cumulatively make up the top 90%
top_90_mask = cumulative_share <= 0.9
top_90_regions = region_counts[top_90_mask]

# Get the ordered list of those region names (most frequent to least within top 90%)
ordered_top_regions = top_90_regions.index.tolist()

#  Output the list
print(" Top 90% Regions (ordered by wine count):")
for region in ordered_top_regions:
    print("-", region)

# === Optional Plot ===
plt.figure(figsize=(12, 6))
top_90_regions.sort_values(ascending=True).plot(kind="barh", color="mediumseagreen")
plt.title("Regions Representing Top 90% of Wines")
plt.xlabel("Number of Wines")
plt.ylabel("Region")
plt.grid(axis="x")
plt.tight_layout()
plt.show()


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347a00ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting station-level features: 100%|██████████| 28/28 [00:21<00:00,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: features saved for each department.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === CONFIGURATION ===\n",
    "src_folder = \"/data/weather_pq/cleaned_parquet\"\n",
    "dst_folder = \"/data/weather_features\"\n",
    "os.makedirs(dst_folder, exist_ok=True)\n",
    "\n",
    "# === TRAITEMENT DE TOUS LES DÉPARTEMENTS ===\n",
    "for file in tqdm(os.listdir(src_folder), desc=\"Extracting station-level features\"):\n",
    "    if not file.endswith(\".parquet\"):\n",
    "        continue\n",
    "\n",
    "    dept = file.split(\"_\")[1].split(\".\")[0]  # Exemple: weather_02.parquet → 02\n",
    "    df = pd.read_parquet(os.path.join(src_folder, file))\n",
    "\n",
    "    # Dates\n",
    "    df[\"AAAAMMJJ\"] = pd.to_datetime(df[\"AAAAMMJJ\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"AAAAMMJJ\"])\n",
    "    df = df[df[\"AAAAMMJJ\"].dt.year >= 2010].copy()\n",
    "    df[\"Year\"] = df[\"AAAAMMJJ\"].dt.year\n",
    "    df[\"month\"] = df[\"AAAAMMJJ\"].dt.month\n",
    "\n",
    "    if \"NUM_POSTE\" not in df.columns:\n",
    "        df[\"NUM_POSTE\"] = \"UNKNOWN_\" + dept\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    # === GROUPÉ PAR STATION + ANNÉE ===\n",
    "    for (station, year), g in df.groupby([\"NUM_POSTE\", \"Year\"]):\n",
    "        grow = g[g[\"month\"].between(4, 10)]\n",
    "        summer = g[g[\"month\"].isin([7, 8])]\n",
    "\n",
    "        try:\n",
    "            gdd = np.maximum((grow[\"TN\"] + grow[\"TX\"]) / 2 - 10, 0).sum()\n",
    "            avg_tm_summer = summer[\"TM\"].mean()\n",
    "            avg_tx_summer = summer[\"TX\"].mean()\n",
    "            temp_amp = (summer[\"TX\"] - summer[\"TN\"]).mean()\n",
    "            hot_days = (summer[\"TX\"] > 35).sum()\n",
    "            rainy_days = (summer[\"RR\"] > 10).sum()\n",
    "            rain_june = g[g[\"month\"] == 6][\"RR\"].sum()\n",
    "            rain_sep_oct = g[g[\"month\"].isin([9, 10])][\"RR\"].sum()\n",
    "            frost_apr = (g[g[\"month\"] == 4][\"TN\"] < 0).sum()\n",
    "            avg_tm_apr = g[g[\"month\"] == 4][\"TM\"].mean()\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        # Géolocalisation (si dispo)\n",
    "        lat = g[\"LAT\"].iloc[0] if \"LAT\" in g.columns else np.nan\n",
    "        lon = g[\"LON\"].iloc[0] if \"LON\" in g.columns else np.nan\n",
    "        alti = g[\"ALTI\"].iloc[0] if \"ALTI\" in g.columns else np.nan\n",
    "\n",
    "        rows.append({\n",
    "            \"dept\": dept,\n",
    "            \"station\": station,\n",
    "            \"year\": year,\n",
    "            \"latitude\": lat,\n",
    "            \"longitude\": lon,\n",
    "            \"altitude\": alti,\n",
    "            \"GDD\": gdd,\n",
    "            \"TM_summer\": avg_tm_summer,\n",
    "            \"TX_summer\": avg_tx_summer,\n",
    "            \"temp_amp_summer\": temp_amp,\n",
    "            \"hot_days\": hot_days,\n",
    "            \"rainy_days_summer\": rainy_days,\n",
    "            \"rain_June\": rain_june,\n",
    "            \"rain_SepOct\": rain_sep_oct,\n",
    "            \"frost_days_Apr\": frost_apr,\n",
    "            \"avg_TM_Apr\": avg_tm_apr\n",
    "        })\n",
    "\n",
    "    # Sauvegarde par département\n",
    "    feat_df = pd.DataFrame(rows)\n",
    "    output_path = os.path.join(dst_folder, f\"weather_features_{dept}.parquet\")\n",
    "    feat_df.to_parquet(output_path, index=False)\n",
    "\n",
    "print(\"Done: features saved for each department.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797f0fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    year  usable_stations\n",
      "0   2010               11\n",
      "1   2011               11\n",
      "2   2012               11\n",
      "3   2013               11\n",
      "4   2014               11\n",
      "5   2015               11\n",
      "6   2016               11\n",
      "7   2017                6\n",
      "8   2018                6\n",
      "9   2019                6\n",
      "10  2020                8\n",
      "11  2021               11\n",
      "12  2022               12\n",
      "13  2023               14\n",
      "14  2024               14\n"
     ]
    }
   ],
   "source": [
    "#Verification of usable station per departments\n",
    "\n",
    "def count_usable_stations_per_dept(department_number):\n",
    "    \"\"\"\n",
    "    input: department_number (str): the number of the department to check\n",
    "    output: Number of stations with complete row data for each year in the department\n",
    "    \"\"\"\n",
    "    dst_folder = '/data/weather_features'\n",
    "    df = pd.read_parquet(os.path.join(dst_folder, f\"weather_features_{department_number}.parquet\"))\n",
    "\n",
    "    feature_cols = [\"GDD\", \"TM_summer\", \"TX_summer\", \"hot_days\", \"temp_amp_summer\",\n",
    "                    \"rainy_days_summer\", \"rain_June\", \"rain_SepOct\", \"frost_days_Apr\", \"avg_TM_Apr\"]\n",
    "\n",
    "    valid_mask = df.groupby([\"year\", \"station\"])[feature_cols].apply(\n",
    "        lambda g: g.notna().all(axis=1).all()\n",
    "    ).reset_index(name=\"is_valid\")\n",
    "\n",
    "    usable_stations_by_year = valid_mask[valid_mask[\"is_valid\"]].groupby(\"year\").size().reset_index(name=\"usable_stations\")\n",
    "\n",
    "    return usable_stations_by_year\n",
    "\n",
    "print(count_usable_stations_per_dept(\"32\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UTOKYO-DL-Projet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
